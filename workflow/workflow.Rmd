---
title: "Bioconductor workflow for single-cell RNA sequencing: Dimensionality reduction, clustering, and lineage inference"
author: 
  - name: Fanny Perraudeau
    affiliation: Graduate Group in Biostatistics, UC Berkeley
  - name: Davide Risso
    affiliation: Division of Biostatistics and Epidemiology, Department of Healthcare Policy and Research, Weill Cornell Medicine
  - name: Kelly Street
    affilitation: Graduate Group in Biostatistics, UC Berkeley
  - name: Elizabeth Purdom
    affiliation: Department of Statistics, UC Berkeley
  - name: Sandrine Dudoit
    affiliation: Division of Biostatistics and Department of Statistics
abstract: Abstracts should be up to 300 words and provide a succinct summary of the article. Although the abstract should explain why the article might be interesting, care should be taken not to inappropriately over-emphasise the importance of the work described in the article. Citations should not be used in the abstract, and the use of abbreviations should be minimized.
keywords: single-cell, single-cell genomics, RNA-seq, gene expression, zero inflation, normalization, clustering, lineage inference, statistical models, workflow, R, Bioconductor
bibliography: ref.bib
vignette: >
    %\VignetteIndexEntry{A worfklow for low-level analyses of scRNA-seq data}
    %\VignetteEngine{knitr::rmarkdown}
output: BiocWorkflowTools::f1000_article
---

```{r options, echo=FALSE, results="hide",message=FALSE, error=FALSE, include=FALSE, autodep=TRUE}
library(BiocStyle)
library(knitr)
knitr::opts_chunk$set(cache=TRUE, error=FALSE, message=FALSE, warning=TRUE)
knitr::opts_chunk$set(fig.align="center", fig.width=5, fig.height=5)

#bioconductor:
library(clusterExperiment)
library(BiocParallel)
library(zinbwave)
#github
library(slingshot)
#library(scone)
#CRAN
library(doParallel)
library(RColorBrewer)
library(gam)
set.seed(20)
if(packageVersion("zinbwave")<'0.99.4.2') stop("must have current develop version to avoid bugs")
```


```{r parallel, echo=FALSE}
runZinb <- TRUE
runClus <- TRUE
NCORES <- 2
mysystem = Sys.info()[['sysname']]
if (mysystem == 'Darwin'){
  registerDoParallel(NCORES)
  register(DoparParam())
}else if (mysystem == 'Linux'){
  register(bpstart(MulticoreParam(workers=NCORES)))
}else{
  print('Please change this to allow parallel computing')
  register(SerialParam())
}
```

EAP: small request. Can everyone put a line between the beginning of a r chunk and text? It makes it nicely formated for my text editor. 

# Introduction

Single-cell RNA sequencing (scRNA-seq) is a powerful and promising class of high-throughput assays that enable researchers to measure genome-wide transcription levels at the resolution of single cells. To properly account for features specific to scRNA-seq, such as zero inflation and high levels of technical noise, several novel statistical methods have been developed to tackle questions that include dimensionality reduction, clustering, and the inference of cell lineages and pseudotimes. While each individual method is useful on its own for addressing a specific question, there is an increasing need for workflows that integrate these tools to yield a seamless scRNA-seq data analysis pipeline. This is all the more true, with novel sequencing technologies that allow an increasing number of cells to be sequenced in each run. For example, the Chromium Single Cell 3' Solution was recently used to sequence and profile about 1.3 million cells from embryonic mouse brains. 

scRNA-seq workflows have already been developed, with several useful methods for quality control, visualization, and pre-processing of the data. The workflow for low-level analysis of scRNA-seq data described in [@Lun2016] or the package `scater` [@McCarthy2017] are examples of workflows based on software packages from the open-source Bioconductor Project [@Huber2015] and cover basic steps, including quality control, data exploration, and normalization. In these workflows, single-cell expression data are organized in objects of the `SCESet` class allowing integrated analysis. However, these workflows are mostly used to prepare the data for further downstream analysis and do not focus on steps like clustering and pseudotime ordering.

Here, we propose an integrated workflow for dowstream analysis, with the following four main steps: (1) dimensionality reduction accounting for zero inflation and adjusting for gene and cell-level covariates; (2) robust and stable clustering using resampling-based sequential ensemble clustering; (3) inference of cell lineages and ordering of the cells by developmental progression; and (4) DE analysis within and between the lineages. Along the workflow, we use a unique `SummarizedExperiment` object to create an easy to use sequence of steps, where a different R package is used for each step.

```{r schema, echo=FALSE, out.width='90%', fig.cap="Workflow for analyzing scRNA-seq datasets. On the right side, major plots generated by the workflow."}
knitr::include_graphics('schema_workflow.png')
```


# Analysis of olfactory stem cell differentiation using scRNA-seq data

## Overview

```{r stemcelldiff, echo=FALSE, out.width='60%', fig.align='center', fig.cap = 'Stem cell differentiation in the mouse olfactory epithelium. This figure has been reproduced with kind permission from (Fletcher et al. 2017).'}
knitr::include_graphics('stemcelldiff_Fletcher2017_2e.png')
```

This workflow is illustrated using data from a scRNA-seq study of stem cell differentiation in the mouse olfactory epithelium (OE) [@Fletcher2017]. The olfactory epithelium contains mature olfactory sensory neurons that are continuously renewed in the epithelium via neurogenesis through differentiation of globose basal cells (GBCs), which are the actively proliferating cells in the epithelium. When a severe injury to the entire tissue happens, the olfactory epithelium can regenerate from normally quiescent stem cells called horizontal basal cells (HBCs) which become activated to differentiate and reconstitute all major cell types in the epithelium.   

The scRNA-seq dataset we work with was generated to study the differentitation of HBCs stem cells into different cell types present in the olfactory epithelium. To map the developmental trajectories of the multiple cell lineages arising from HBCs, scRNA-seq was performed on FACS-purified cells using the Fluidigm C1 microfluidics cell capture platform followed by Illumina sequencing. Then, the expression level of each gene in a given cell was quantified by counting the total number of reads mapping to it. Cells were then assigned to different lineages using a statistical analysis pipeline analogous to that in the present workflow. Finally, results were validated experimentally using in vivo lineage tracing. Details on data generation and statistical methods are available in [@Fletcher2017] [@Risso2017], and [@Street2017].

It was found that the first major bifurcation in the HBC lineage trajectory occurs prior to cell division, producing either mature sustentacular (mSUS) cells or GBCs. Then, the GBC lineage, in turn, branches off to give rise to mature olfactory sensory neurons (mOSN), microvillous (MV) cells, and cells of the Bowman gland. See Figure \@ref(fig:stemcelldiff). In this study, we describe a sequence of steps to recover the lineages found in the original study, starting from the genes x cells matrix of raw counts publicly-available at https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE95601.

FP: ask Russell if we can use the Figure \@ref(fig:stemcelldiff) here.

## Pre-processing

Counts for all genes in each cell were obtained from NCBI Gene Expression Omnibus (GEO) with accession number GSE95601. Before filtering, the dataset has 849 cells and 28,361 detected genes (i.e., genes with non-zero read counts). 

```{r, echo = FALSE}
urls = c("https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE95601&format=file&file=GSE95601%5FoeHBCdiff%5FCufflinks%5FeSet%2ERda%2Egz",
         "https://raw.githubusercontent.com/rufletch/p63-HBC-diff/master/ref/oeHBCdiff_clusterLabels.txt")
         
if(!file.exists("../data/GSE95601_oeHBCdiff_Cufflinks_eSet.Rda")) {
  download.file(urls[1], "../data/GSE95601_oeHBCdiff_Cufflinks_eSet.Rda.gz")
  gunzip("../data/GSE95601_oeHBCdiff_Cufflinks_eSet.Rda.gz")
}

if(!file.exists("../data/oeHBCdiff_clusterLabels.txt")) {
  download.file(urls[2], "../data/oeHBCdiff_clusterLabels.txt")
}
```

```{r}
load("../data/GSE95601_oeHBCdiff_Cufflinks_eSet.Rda")

# count matrix
E <- assayData(Cufflinks_eSet)$counts_table

# Remove undetected genes
E <- na.omit(E)
E <- E[rowSums(E)>0,]
dim(E)
```

We remove the ERCC spike-in sequences and the CreER gene as it corresponds to a marker gene for HBCs. Davide, is that correct?

```{r}
# remove ERCC and CreER genes
cre <- E["CreER",]
ercc <- E[grep("^ERCC-", rownames(E)),]
E <- E[grep("^ERCC-", rownames(E), invert = TRUE), ]
E <- E[-which(rownames(E)=="CreER"), ]
dim(E)
```

Throughout the workflow, we use an object of class `SummarizedExperiment` to keep track of the counts and their associated metadata within a single object. The cell-level metadata contain quality control (QC) measures, sequencing batche ID, and cluster labels and lineage labels from the original publication [@Fletcher2017]. Cells with a cluster label of `-2` were not assigned to a cluster in the original publication.

```{r}
# Extract QC metrics
qc <- as.matrix(protocolData(Cufflinks_eSet)@data)[,c(1:5, 10:18)]
qc <- cbind(qc, CreER = cre, ERCC_reads = colSums(ercc))

# Extract metadata
batch <- droplevels(pData(Cufflinks_eSet)$MD_c1_run_id)
bio <- droplevels(pData(Cufflinks_eSet)$MD_expt_condition)
clusterLabels <- read.table("../data/oeHBCdiff_clusterLabels.txt",
                            sep = "\t", stringsAsFactors = FALSE)
m <- match(colnames(E), clusterLabels[, 1])

# Create metadata data.frame
metadata <- data.frame("Experiment" = bio,
                       "Batch" = batch,
                       "clusterLabels" = clusterLabels[m,2],
                       qc)

# symbol for cell not assigned to a lineage in original data
metadata$clusterLabels[is.na(metadata$clusterLabels)] <- -2

se <- SummarizedExperiment(assays = list(counts = E),
                           colData = metadata)
se
```

Using the Bioconductor R package `scone` [SD: scone not yet released on Bioconductor], we remove low-quality cells that did not pass our quality control filter, that is ... See Figure \@ref(fig:scone). Davide, would you like to describe your choices for scone here?

```{r scone, fig.cap="Plot generated by scone to filter low quality cells.", eval=FALSE}
# Metric-based Filtering sample-filtering
data("housekeeping")
hk = rownames(se)[toupper(rownames(se)) %in% housekeeping$V1]

mfilt <- metric_sample_filter(assay(se), 
                              nreads = colData(se)$NREADS,
                              ralign = colData(se)$RALIGN,
                              pos_controls = rownames(se) %in% hk,
                              zcut = 3, mixture = FALSE,
                              plot = TRUE)
```

```{r sconeFilt, eval=FALSE}
# Simplify to a single logical
mfilt <- !apply(simplify2array(mfilt[!is.na(mfilt)]), 1, any)
se <- se[, mfilt]
dim(se)
```

Finally, to speed up the computations, we retain only the 1,000 most variable genes. We recommend, however, not to be so stringent in your actual data analysis.

```{r,eval=FALSE}
# Filtering to top 1000 most variable
vars <- rowVars(log1p(assay(se)))
names(vars) <- rownames(se)
vars <- sort(vars, decreasing = TRUE)
core <- se[names(vars)[1:1000],]
```

```{r}
load("../data/oe_se_1000Var.rda")
```


## Dataset structure

Overall, after the pre-processing steps, our dataset has 1,000 genes and 747 cells.
```{r}
core
```

Metadata for the cells are stored in the slot `colData` from the `SummarizedExperiment` object. Cells were processed in 18 different batches.

```{r batch}
batch <- colData(core)$Batch
col_batch = c(brewer.pal(9, "Set1"), brewer.pal(8, "Dark2"), 
              brewer.pal(8, "Accent")[1])
names(col_batch) = unique(batch)
table(batch)
```

In the original work [@Fletcher2017], cells were clustered into 14 different clusters, where 151 cells have a cluster label of `-2`, that is they were not assigned to a cluster in the original publication. [SD: -2 labels? FP: yes]

```{r original}
clus.labels <- colData(core)[, "clusterLabels"]
col_clus <- c("transparent", brewer.pal(12, "Set3"), brewer.pal(8, "Set2"))
col_clus <- col_clus[1:length(unique(clus.labels))]
names(col_clus) <- sort(unique(clus.labels))
table(clus.labels)
```

Note that there is partial nesting [SD: Did you mean nesting? FP: yes] of batches and clusters, which could be problematic when correcting for batch effects in the dimensionality reduction step.

```{r clustbatch}
table(data.frame(batch = as.vector(batch),
                 cluster = clus.labels))
```

## Normalization and dimensionality reduction: ZINB-WaVE

In scRNA-seq analysis, dimensionality reduction is often used as a preliminary step prior to downstream analyses, such as clustering, cell lineage and pseudotime ordering, and differential expression (DE) analysis. This allows the data to become more tractable, both from a statistical (cf. curse of dimensionality) and computational point of view. Additionally, technical noise can be reduced while preserving the often intrinsically low dimensional signal of interest [@Peer2017] [@Risso2017][@Pierson2015].

Here, we perform dimensionality reduction using the Bioconductor R package `zinbwave`, which fits a zero-inflated negative binomial model (ZINB-WaVE) that accounts for zero inflation (dropouts), over-dispersion, and the count nature of the data. The model can include a sample-level intercept, which serves as a global-scaling normalization factor. The user can also include both gene-level and sample-level covariates. The inclusion of observed and unobserved sample-level covariates enables normalization for complex, non-linear effects (often referred to as batch effects), while gene-level covariates may be used to adjust for sequence composition effects, such as gene length and GC-content effects. See a schematic view of the ZINB-WaVE model in Figure \@ref(fig:zinbschema). For greated detail about the ZINB-WaVE model and estimation procedure, please refer to the original manuscript [@Risso2017].

```{r zinbschema, echo=FALSE, out.width='95%', fig.cap="Schematic view of the ZINB-WaVE model. This figure has been reproduced with kind permission from (Risso et al. 2017)."}
knitr::include_graphics('zinb_schema.pdf')
```

As with most dimensionality reduction methods, the user needs to specify the number of dimensions for the new low-dimensional space. Here, we use `K = 50` dimensions and adjust for batch effects. 

```{r zinb}
fn <- '../data/zinb_batch.rda'
if (runZinb & !file.exists(fn)){
  print(system.time(se <- zinbDimRed(core, K = 50, X = '~ Batch',
                                       residuals = TRUE,
                                       normalizedValues = TRUE)))
  save(se, file = fn)
}else{
  load(fn)
}
```

DR: the chunk above and the similar one for clusterExperiment are fine for now, but in the published workflow, we should just rely on the markdown cache system (the code above doesn't check for changes to the file or code -- just that a version of the file exists). FP: Yes.

### Normalization

The function `zinbDimRed` returns normalized expression measures as deviance residuals from the fit of the ZINB-WaVE model with user-supplied gene- and cell-level covariates. Such residuals can be used for visualization purposes (e.g., in heatmaps, boxplots). Note that in this case no low-dimensional matrix is computed, as some of the biological signal of interest could be removed when computing residuals with respect to this matrix. 

```{r norm}
norm <- assays(se)$normalizedValues
if (sum(is.infinite(norm))>0){
  maxNorm = max(norm[!is.infinite(norm)])
  assays(se)$normalizedValues[is.infinite(norm)] <- maxNorm
  norm <- assays(se)$normalizedValues
}
norm[1:3,1:3]
```

As expected, the normalized values no longer exhibit batch effects (Figure \@ref(fig:boxplotNorm)).

```{r boxplotNorm, fig.cap="Boxplots of normalized expression measures, color-coded by batch."}
norm_order <- norm[, order(as.numeric(batch))]
col_order <- col_batch[batch[order(as.numeric(batch))]]
boxplot(norm_order, col = col_order, staplewex = 0, outline = 0,
        border = col_order, xaxt = 'n')
abline(h=0)
```

The principal component analysis (PCA) of the normalized values shows that, as expected, cells do not cluster by batch but by the orginal clusters (Figure \@ref(fig:pcanorm)). Overall, it seems that normalization was effective at removing batch effects.

```{r pcanorm, fig.cap="PCA of normalized expression measures, where each point represents a cell. In the left panel, cells are color-coded by batch. In the right panel, cells are color-coded by original published clusters."}
pca <- prcomp(t(norm))
par(mfrow = c(1,2))
plot(pca$x, col = col_batch[batch], pch = 20, main = '')
plot(pca$x, col = col_clus[as.character(clus.labels)], pch = 20, main = '')
```

```{r,echo=FALSE}
par(mfrow = c(1,1))
```

### Dimensionality reduction

The `zinbDimRed` function can also be used to perform dimensionality reduction, where in this workflow the user-supplied dimension `K` of the low-dimensional space is set to `K = 50`. The resulting low-dimensional matrix `W` can be visualized in two dimensions by performing multi-dimensional scaling (MDS) using the Euclidian distance. To verify that `W` indeed captures the biological signal of interest, we display the MDS results with colors corresponding to the original published clusters (Figure \@ref(fig:mdsW)).

```{r mdsW, fig.cap="MDS of the low-dimensional matrix W, where each point represents a cell and cells are color-coded by original published clusters."}
W <- colData(se)[, grepl('^W', colnames(colData(se)))]
W <- as.matrix(W)
d <- dist(W)
fit <- cmdscale(d, eig = TRUE, k = 2)
plot(fit$points, col = col_clus[as.character(clus.labels)], main = '',
     pch = 20, xlab = 'Component 1', ylab = 'Component 2')
legend(x = 'bottomright', legend = unique(names(col_clus)), cex = .5,
       fill = unique(col_clus), title = 'Sample')
```

## Cell clustering: RSEC

The next step of the workflow is to cluster the cells according to the low-dimensional matrix `W` computed in the previous step. We use the resampling-based sequential ensemble clustering (RSEC) frameworkd implemented in the `RSEC` function from the Bioconductor R package `clusterExperiment`. Specifically, given a set of user-supplied based clustering algorithms and associated tuning parameters (e.g., `k`-means, with a range of values for `k`), RSEC generates a collection of candidate clusterings by resampling cells and using a sequential tight clustering procedure as in Tseng and Wong (2005)[@Tseng2005]. A consensus clustering is obtained based on the co-clustering matrix and non-differential clusters are then merged by creating a hierarchy of clusters, working up the tree, testing for differential expression between sister nodes, and collapsing nodes with insufficient DE. As in supervised learning, resampling greatly improves the stability of clusters and considering an ensemble of methods and tuning parameters allows us to capitalize on the different strengths of the base algorithms and avoid the subjective selection of tuning parameters. 

Elizabeth, would you like to more details on the rational and arguments of the different functions?

```{r rsec_50}
fn <- '../data/RSEC_W_combineMinSize10.rda'
if (runClus & !file.exists(fn)){
  #symbol for samples missing from original clustering
  seObj <- SummarizedExperiment(t(W), colData = colData(core))
  print(system.time(ceObj <- RSEC(seObj, k0s = 4:15, alphas = c(0.1),
                                  betas = 0.8, dimReduce="none",
                clusterFunction = "hierarchical01", minSizes=1,
                ncores = NCORES, isCount=FALSE,
                subsampleArgs = list(resamp.num=100,
                                     clusterFunction="kmeans",
                                     clusterArgs=list(nstart=10)),
                seqArgs = list(k.min=3, top.can=5), verbose=TRUE,
                combineProportion = 0.7,
                mergeMethod = "none", random.seed=424242,
                combineMinSize = 10)))
  save(ceObj, file = fn)
}else{
  load(fn)
}
```

The resulting candidate clusterings can be visualized using the `plotClusters` function (Figure \@ref(fig:examineCombineMany)), where columns correspond to cells and rows to different clusterings. Each sample is color-coded based on its clustering for that row, where the colors have been chosen to try to match up clusters across different clusterings that show large overlap. The first row correspond to a consensus clustering across all candidate clusterings.

```{r examineCombineMany, fig.cap="Clusters found using the function RSEC from the clusterExperiment package."}
plotClusters(ceObj, colPalette = c(bigPalette, rainbow(199)))
```

The `plotCoClustering` function produces a heatmap of the co-clustering matrix, which records, for each pair of cells, the proportion of times they were clustered together across the candidate clusters (Figure \@ref(fig:plotcoclust)). 

```{r plotcoclust, fig.cap="Heatmap of co-clustering matrix."}
plotCoClustering(ceObj)
```

The distribution of cells across the consensus clusters is as follows:

```{r tableclust}
table(primaryClusterNamed(ceObj))
```

Figure \@ref(fig:heatmapsClusters) displays a heatmap of the normalized expression measures for the 1,000 most variable genes, where cells are clustered according to the RSEC consensus.

```{r heatmapsClusters, fig.cap="Heatmap of the normalized expression measures for the 1,000 most variable genes, where rows correspond to genes and columns to cells ordered by RSEC clusters."}
# Set colors for cell clusterings
colData(ceObj)$clusterLabels <- as.factor(colData(ceObj)$clusterLabels)
origClusterColors <- bigPalette[1:nlevels(colData(ceObj)$clusterLabels)]
experimentColors <- bigPalette[1:nlevels(colData(ceObj)$Experiment)]
batchColors <- bigPalette[1:nlevels(colData(ceObj)$Batch)]
metaColors <- list("Experiment" = experimentColors,
                   "Batch" = batchColors,
                   "clusterLabels" = origClusterColors)

plotHeatmap(ceObj, visualizeData = assays(se)$normalizedValues,
            whichClusters = "primary", clusterFeaturesData = "all",
            clusterSamplesData = "dendrogramValue", breaks = 0.99,
            sampleData = c("clusterLabels", "Batch", "Experiment"),
            clusterLegend = metaColors, annLegend = FALSE, main = '')
```

Finally, we can visualize the cells in a two-dimensional space using the MDS of the low-dimensional matrix `W` and coloring the cells according to their newly-found RSEC clusters (Figure \@ref(fig:mdsWce)); this is anologous to Figure \@ref(fig:mdsW) for the original published clusters.

```{r mdsWce, fig.cap="MDS of the low-dimensional matrix W, where each point represents a cell and cells are color-coded by RSEC clusters."}
palDF <- ceObj@clusterLegend[[1]]
pal <- palDF[, 'color']
names(pal) <- palDF[, 'name']
pal["-1"] = "transparent"
plot(fit$points, col = pal[primaryClusterNamed(ceObj)], main = '', pch = 20,
     xlab = 'Component1', ylab = 'Component2')
legend(x = 'bottomright', legend = names(pal), cex = .5,
       fill = pal, title = 'Sample')
```

## Cell lineage and pseudotime inference: Slingshot

We now want to demonstrate how to use the R software package `slingshot` to infer branching lineages and order cells by developmental progression. We connect the clusters identified by `RSEC` with a minimum spanning tree (MST) to learn the global lineage structure. Then, we refine this structure and order cells using highly stable simultaneous principal curves to infer smooth, branching lineages. 

From the original published work, we know that the start clusters should be the clusters with HBCs and end clusters the clusters with MV, mOSN, and mSUS cells. Additionally, we know that the clusters with the GBCs should be a junction before the differentiation between MV and mOSN cells. See Figure \@ref(fig:stemcelldiff). The correspondance between the clusters we found and the original clusters is as follow

```{r tabagain}
table(data.frame(original = clus.labels, ours = primaryClusterNamed(ceObj)))
```

Cluster name | Description | Color | Correspondence
-------------|-------------|-------| ----------
c1 | HBCs | blue | original 1, 5
c2 | GBCs | green | original 2, 3, 11
c3 | mSUS | red | original 4, 7
c4 | mOSN | orange | original 9, 12
c5 | Immature Neuron | purple | original 10, 14
c6 | MV | brown | original 15

To order the clusters and find lineages, we use package `slingshot` where the input is the MDS of low dimensional matrix `W` where the number of dimensions used for MDS is `k = 4`. We found that slingshot algorithm is stable to the number of dimensions `k` of the MDS. Here, we use the unsupervised version of slingshot where we only provide the information of the start cluster but not the end clusters. Using slingshot, we recovered the order of the clusters found in the published work. See Figures \@ref(fig:curves) and \@ref(fig:tree).

The two steps of the slingshot algorithm are implemented in the functions 'getLineages' and 'getCurves'. The first takes the low-dimensional representation of the cells and the vector of cluster labels identified above. It fits an MST to the clusters and identifies lineages as paths through this tree. The output of 'getLineages' is a 'SlingshotDataSet' object containing all the information used to fit the tree and identify lineages. 'getCurves' takes this object as input and fits simultaneous principal curves to the identified lineages. These functions can be run separately, as below, or jointly by the wrapper function, 'slingshot'.

```{r}
our_cl <- primaryClusterNamed(ceObj)
cl = our_cl[our_cl != "-1"]
pal = pal[names(pal) != '-1']
X <- W[our_cl != "-1", ]
mds <- cmdscale(dist(X), eig = TRUE, k = 4)
X <- mds$points

lineages <- getLineages(X, clusterLabels = cl, start.clus = "c1")
lineages <- getCurves(lineages)
```

```{r curves, fig.cap="Cells colored by cluster in a 4-dimensional space with smooth curves representing each inferred lineage."}
pairs(lineages, type='curves', pal[primaryClusterNamed(ceObj)])
```

```{r tree, fig.cap="Cells colored by cluster in a 4-dimensional space with connecting lines between cluster centers representing the inferred structure."}
pairs(lineages, type='lineages', col = pal[primaryClusterNamed(ceObj)])
```

```{r lineages}
lineages
```

In the workflow, we recover a reasonable pseudotime ordering of the clusters using the unsupervised version of slingshot. However, in some other cases, we have noticed that we need to give more guidance to the algorithm to find the correct ordering. 'getLineages' has the option for the user to provide known end cluster(s). Here is the code to use slingshot in a supervised setting: 

```{r slingshotsupervised, eval=FALSE}
lineages <- getLineages(X, clusterLabels = cl, start.clus = "c1",
                         end.clus = c("c3", "c6"))
lineagees <- getCurves(lineages)
pairs(lineages, type='curves', pal[primaryClusterNamed(ceObj)])
pairs(lineages, type='lineages', col = pal[primaryClusterNamed(ceObj)])

lineages
```

## Differential expression analysis

After ordering the cells, we are interested in finding genes that have non-constant expression patterns over pseudotime. We can see global trends in expression by subsetting our original data to the most variable genes and plotting their expression values in a heatmap, ordered by pseudotime.

More formally, we are interested in testing for variable expression over pseudotime. A general additive model (GAM) is a flexible, nonlinear way to test the relationship between a gene's normalized expression values and pseudotime. We implemented this model for each gene and show the top 100 genes by p-value in the heatmap below.

```{r fitgam}
t <- pseudotime(lineages)[,1]
y <- assays(se)$normalizedValues[, our_cl != "-1"]
gam.pval <- apply(y,1,function(z){
  d <- data.frame(z=z, t=t)
  tmp <- gam(z ~ lo(t), data=d)
  p <- summary(tmp)[4][[1]][1,5]
  p
})
```


```{r heatmapsignificant}
topgenes <- names(sort(gam.pval, decreasing = FALSE))[1:100]
heatdata <- y[rownames(se) %in% topgenes, order(t, na.last = NA)]
heatclus <- cl[order(t, na.last = NA)]
ce <- clusterExperiment(heatdata, heatclus, transformation = identity)
plotHeatmap(ce, clusterSamplesData = "orderSamplesValue", breaks = .99)
```

## Further developments

In an effort to improve scRNA-seq data analysis workflows, we are currently exploring a variety of applications and extensions of our ZINB-WaVE model. In particular, we are developing a method to impute counts for dropouts; the imputed counts could be used in subsequent steps of the workflow, including dimensionality reduction, clustering, and cell lineage inference. ZINB-WaVE can also be used for identifying genes that are differentially expressed between cells, both in terms of the negative binomial mean and the zero inflation probability, reflecting, respectively, gradual DE and on/off DE patterns. We are also developing a method to identify genes that are DE either within or between lineages inferred from Slingshot. 

Finally, a new R class called `SingleCellExperiment` should be released soon. This new class would essentially be a `SummarizedExperiment` class with a couple of additional slots, the most important of which is `reducedDims`, which, much like the `assays` slot of `SummarizedExperiment` can contain one or more matrices of reduced dimension. This new `SingleCellExperiment` class would be a valuable addition to the workflow, as we could store in a single object the raw counts as well as the low-dimensional matrix created by the ZINB-WaVE dimensionality reduction step. Once this class is implemented, we would like to incorporate it to the workflow.

# Conclusion

This workflow provides a tutorial for the downstream analysis of scRNA-seq data in R. The workflow covers four main steps: (1) dimensionality reduction accounting for zero inflation and adjusting for gene and cell-level covariates; (2) robust and stable clustering using resampling-based sequential ensemble clustering; (3) inference of cell lineages and ordering of the cells by developmental progression; and (4) DE analysis within and between the lineages. The workflow is general and flexible, allowing the user to sustitute the statistical method used in each step by a different method. We hope our proposed workflow will ease the technical aspect of scRNA-seq data analysis and help with the discovery of novel biological insights.

# Software availability
This section will be generated by the Editorial Office before publication. Authors are asked to provide some initial information to assist the Editorial Office, as detailed below.

1. URL link to where the software can be downloaded from or used by a non-coder (AUTHOR TO PROVIDE; optional)
2. URL link to the author's version control system repository containing the source code (AUTHOR TO PROVIDE; required)
3. Link to source code as at time of publication (*F1000Research* TO GENERATE)
4. Link to archived source code as at time of publication (*F1000Research* TO GENERATE)
5. Software license (AUTHOR TO PROVIDE; required)

The four packages used in the workflow (scone, zinbwave, clusterExperiment, and slingshot) are bioconductor packages and are available on github at respectively https://github.com/YosefLab/scone, https://github.com/drisso/zinbwave, https://github.com/epurdom/clusterExperiment, and https://github.com/kstreet13/slingshot. The source code for this package can be found at https://github.com/fperraudeau/singlecellworkflow under license XXX. 

```{r}
sessionInfo()
```

# Author contributions
In order to give appropriate credit to each author of an article, the individual contributions of each author to the manuscript should be detailed in this section. We recommend using author initials and then stating briefly how they contributed.

# Competing interests
All financial, personal, or professional competing interests for any of the authors that could be construed to unduly influence the content of the article must be disclosed and will be displayed alongside the article. If there are no relevant competing interests to declare, please add the following: 'No competing interests were disclosed'.

# Grant information
Please state who funded the work discussed in this article, whether it is your employer, a grant funder etc. Please do not list funding that you have that is not relevant to this specific piece of research. For each funder, please state the funderâ€™s name, the grant number where applicable, and the individual to whom the grant was assigned. If your work was not funded by any grants, please include the line: 'The author(s) declared that no grants were involved in supporting this work.'

# Acknowledgments
This section should acknowledge anyone who contributed to the research or the
article but who does not qualify as an author based on the criteria provided earlier (e.g. someone or an organization that provided writing assistance). Please state how they contributed; authors should obtain permission to acknowledge from all those mentioned in the Acknowledgments section.

# References
